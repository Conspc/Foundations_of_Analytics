{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New package installation\n",
    "```pip install tensorflow_datasets```\n",
    "\n",
    "```pip install ipywidgets```\n",
    "\n",
    "```pip install nltk```\n",
    "### Reference:\n",
    "https://www.tensorflow.org/tutorials/text/word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Data/J. K. Rowling - Harry Potter 1 - Sorcerer's Stone\",'r')\n",
    "raw_data_1 = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "import nltk \n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "word_tokens = wordpunct_tokenize(raw_data_1)  \n",
    "word_tokens = [w.lower() for w in word_tokens if not w in stop_words] \n",
    "word_tokens = [w.lower() for w in word_tokens if w.isalpha()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(word_tokens)\n",
    "char_to_int = dict((c,i) for i,c in enumerate(vocab))\n",
    "int_to_char = dict((i,c) for i,c in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([], dtype=np.float).reshape(0,4)\n",
    "Y = np.array([])\n",
    "Xwords=[]\n",
    "Ywords=[]\n",
    "window_size = 2\n",
    "for i, word in enumerate(word_tokens):\n",
    "    Xsub=np.zeros(2*window_size)\n",
    "    Xsubwords=[]\n",
    "    isetvalue=0\n",
    "    for icontext in range(max(i-window_size,0), min(i+window_size, len(word_tokens)-1)+1):\n",
    "        if icontext!=i:\n",
    "            Xsub[isetvalue]=char_to_int[word_tokens[icontext]]\n",
    "            Xsubwords.append(word_tokens[icontext])\n",
    "            isetvalue=isetvalue+1\n",
    "    X=np.vstack([X, Xsub])\n",
    "    Xwords.append(Xsubwords)\n",
    "    Y=np.append(Y,char_to_int[word])\n",
    "    Ywords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5482.0]\n",
      "[1947.0]\n"
     ]
    }
   ],
   "source": [
    "print([X[0][1]])\n",
    "print([Y[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=100\n",
    "vocab_size=len(vocab)\n",
    "cbowNN = keras.Sequential([\n",
    "    layers.Embedding(vocab_size, embedding_dim),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbowNN.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45231 samples\n",
      "Epoch 1/10\n",
      "45231/45231 [==============================] - 22s 483us/sample - loss: 7.5646 - accuracy: 0.0307\n",
      "Epoch 2/10\n",
      "45231/45231 [==============================] - 22s 480us/sample - loss: 7.2158 - accuracy: 0.0397\n",
      "Epoch 3/10\n",
      "45231/45231 [==============================] - 22s 482us/sample - loss: 7.0520 - accuracy: 0.0513\n",
      "Epoch 4/10\n",
      "45231/45231 [==============================] - 23s 503us/sample - loss: 6.8633 - accuracy: 0.0598\n",
      "Epoch 5/10\n",
      "45231/45231 [==============================] - 23s 513us/sample - loss: 6.6308 - accuracy: 0.0694\n",
      "Epoch 6/10\n",
      "45231/45231 [==============================] - 22s 494us/sample - loss: 6.3545 - accuracy: 0.0814\n",
      "Epoch 7/10\n",
      "45231/45231 [==============================] - 22s 495us/sample - loss: 6.0483 - accuracy: 0.0955\n",
      "Epoch 8/10\n",
      "45231/45231 [==============================] - 23s 501us/sample - loss: 5.7261 - accuracy: 0.1134\n",
      "Epoch 9/10\n",
      "45231/45231 [==============================] - 23s 504us/sample - loss: 5.3974 - accuracy: 0.1321\n",
      "Epoch 10/10\n",
      "45231/45231 [==============================] - 23s 510us/sample - loss: 5.0706 - accuracy: 0.1545\n"
     ]
    }
   ],
   "source": [
    "history = cbowNN.fit(X, Y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1947"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int[\"harry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4788"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int[\"potter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harry'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_char[1947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pellets'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_char[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1257097"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "e = cbowNN.layers[0]\n",
    "a=e(tf.constant(char_to_int['stone'])).numpy()\n",
    "b=e(tf.constant(char_to_int['harry'])).numpy()\n",
    "np.dot(a,b)/norm(a)/norm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5817012 ,  0.11552174, -0.50672746, -0.76676583,  0.15401813,\n",
       "       -0.6681709 , -0.71469826, -0.61663234,  0.12586027, -0.5183265 ,\n",
       "       -0.40008894, -0.4398571 ,  0.0119456 , -0.75455415,  0.2741087 ,\n",
       "       -0.46714088, -1.201626  , -0.81872886,  0.4370791 ,  0.77879894,\n",
       "       -0.8572957 , -0.6878351 ,  0.9252831 , -0.68646735,  0.5330421 ,\n",
       "        0.31523493,  0.49670088, -0.47646615,  0.91890687,  0.5631099 ,\n",
       "        0.06969263, -0.8544153 , -0.84899163, -0.7981884 ,  0.04232222,\n",
       "        0.05061456,  0.4748415 ,  0.7895601 , -0.42458475,  0.638358  ,\n",
       "       -0.281402  , -1.5851709 , -0.05116541, -0.57948965, -0.91488653,\n",
       "       -0.04604899, -0.529991  , -0.04008646, -0.11312816,  0.6267403 ,\n",
       "       -0.53496647,  0.2150093 , -0.04823145, -0.5373095 , -0.19713253,\n",
       "       -0.71456957,  0.31499422, -0.11559291,  0.03633097, -0.6609817 ,\n",
       "        0.13168311,  0.8367661 ,  0.56946206, -0.9807432 ,  0.38796842,\n",
       "        0.5526397 , -0.78772616,  0.37516588, -0.9905758 , -0.5428416 ,\n",
       "       -0.6359617 ,  0.7342471 , -0.24818996, -0.18199287,  0.72968805,\n",
       "       -0.14221284, -0.82106745, -0.5266826 , -0.82267994,  0.02294496,\n",
       "       -0.45123163, -0.40808097,  0.44259554, -0.26952338,  0.6724441 ,\n",
       "       -0.17403075,  0.51257527,  0.34704453,  0.5010275 ,  0.8828663 ,\n",
       "        0.3129546 , -1.3051957 ,  0.23271485,  0.94946975, -0.3641762 ,\n",
       "       -0.7479144 , -0.08141217, -0.5967825 ,  0.04631939,  0.70293456],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.get_weights()[0][1947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2948307e-22, 3.2295737e-35, 4.3348098e-26, ..., 1.5308596e-27,\n",
       "        1.0985353e-19, 2.6982707e-24]], dtype=float32)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbowNN.predict(tf.constant([3767]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4196"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(cbowNN.predict(tf.constant([3767]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potter\n",
      "felt\n",
      "council\n",
      "shook\n",
      "whispered\n"
     ]
    }
   ],
   "source": [
    "len(cbowNN.predict(tf.constant([char_to_int['stone']]))[0])\n",
    "for i in np.argsort(cbowNN.predict(tf.constant([1947]))[0])[::-1][:5]:\n",
    "    print(int_to_char[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8548\n",
      "15077\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(words):\n",
    "    if word==\"ink\":\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5730, 5730)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# compute pairwise distance matrix\n",
    "distance_matrix = cosine_similarity(e.get_weights()[0])\n",
    "print(distance_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree': ['peering', 'tasted', 'befuddle', 'coast', 'treble'],\n",
       " 'potter': ['treble', 'secret', 'town', 'cloak', 'forests'],\n",
       " 'stone': ['flock', 'sneaking', 'sniffling', 'story', 'dazed'],\n",
       " 'bird': ['pulling', 'cast', 'forests', 'proof', 'applause'],\n",
       " 'girl': ['nonstop', 'forests', 'town', 'beats', 'cast']}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view contextually similar words\n",
    "similar_words = {search_term: [int_to_char[idx] for idx in distance_matrix[char_to_int[search_term]-1].argsort()[1:6]+1] \n",
    "                   for search_term in ['tree', 'potter', 'stone', 'bird', 'girl']}\n",
    "\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
